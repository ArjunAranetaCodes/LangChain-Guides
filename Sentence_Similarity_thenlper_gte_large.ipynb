{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Sentence similarity** is an essential task in natural language processing (NLP), which measures how close two sentences are in meaning. It has numerous applications, including text classification, summarization, information retrieval, and chatbot development. This tutorial will guide you on implementing sentence similarity using the Sentence Transformer library in Python. We'll also dive into understanding each line of code used for calculating sentence embeddings and their cosine similarities."
      ],
      "metadata": {
        "id": "Y-Ad-TVJCwhi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vvrv8jEWGGh"
      },
      "outputs": [],
      "source": [
        "!pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "id": "S4-myc-4ctXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from sentence_transformers.util import cos_sim\n",
        "\n",
        "sentences = ['sorting algorithms', 'That is a very happy person']\n",
        "\n",
        "model = SentenceTransformer('thenlper/gte-large')\n",
        "embeddings = model.encode(sentences)\n",
        "print(cos_sim(embeddings[0], embeddings[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MwTlHahcUDL",
        "outputId": "6d1c0ede-bf6f-4fa8-f214-767797bae5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7201]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**pip install -U sentence-transformers**: Upgrades or installs the latest version of the Sentence Transformers package from PyPI. Sentence Transformers provides pre-trained models that convert sentences into vector space representations (sentence embeddings).\n",
        "\n",
        "The **'thenlper/gte-large'** model generates high-quality sentence embeddings suitable for comparing semantic similarity between pairs of sentences.\n",
        "\n",
        "**!pip install torch**: Install Pytorch if not already installed, ensuring compatibility with your system configuration. Sentence Transformers use Pytorch deep learning framework under the hood.\n",
        "\n",
        "Step 2: Import necessary modules"
      ],
      "metadata": {
        "id": "coIWkPGyCiZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "from transformers import AutoTokenizer, AutoModel"
      ],
      "metadata": {
        "id": "6U6y99c6CYLD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**torch.nn.functional as F**: Imports specific functions like F.normalize() from Pytorch.\n",
        "\n",
        "**Tensor**: A tensor class provided by Pytorch representing multi-dimensional arrays.\n",
        "\n",
        "**AutoTokenizer, AutoModel**: Classes imported from Hugging Face Transformers, providing functionalities for encoding input texts and generating corresponding sentence embeddings.\n",
        "\n",
        "Step 3: Define helper function"
      ],
      "metadata": {
        "id": "JzoqZRDwCbJ7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def average_pool(last_hidden_states: Tensor,\n",
        "                 attention_mask: Tensor) -> Tensor:"
      ],
      "metadata": {
        "id": "GlDTc6bmCXa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
        "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]"
      ],
      "metadata": {
        "id": "LAgmSilLCL7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**last_hidden = last_hidden_states.masked_fill(...)**: Replaces invalid positions marked by ~attention_mask with zeros.\n",
        "\n",
        "**return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]**: Calculates the sum of all elements across axis 1 (sequence length), then divides it by the number of actual tokens present in respective vectors after accounting for padding.\n",
        "\n",
        "Step 4: Prepare input data & generate sentence embeddings"
      ],
      "metadata": {
        "id": "gRtKYdQQCOVI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = [\n",
        "    \"what is the capital of Philippines?\",\n",
        "    \"how to implement quick sort in python?\",\n",
        "    \"Manila\",\n",
        "    \"sorting algorithms\"\n",
        "]\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-large\")\n",
        "model = AutoModel.from_pretrained(\"thenlper/gte-large\")\n",
        "\n",
        "# Tokenize the input texts\n",
        "batch_dict = tokenizer(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "outputs = model(**batch_dict)\n",
        "embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])"
      ],
      "metadata": {
        "id": "tyeOG-ngByo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize input_texts list containing sample questions.\n",
        "\n",
        "* Load pre-trained tokenizer and model.\n",
        "* Encode input texts using tokenizer returning batched tensors ready for feeding into the model.\n",
        "* Generate output features from the model given encoded inputs.\n",
        "* Compute sentence embeddings via our previously defined average_pool method.\n",
        "\n",
        "Step 5: Normalizing embeddings (Optional)"
      ],
      "metadata": {
        "id": "3djtojGpCDs3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = F.normalize(embeddings, p=2, dim=1)"
      ],
      "metadata": {
        "id": "4xpyoQ_CB7xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizes the embeddings so they have unit length, typically improving downstream tasks' performance since distances become comparable regardless of magnitudes.\n",
        "\n",
        "Step 6: Computing pairwise similarity scores"
      ],
      "metadata": {
        "id": "diXAabhKBweE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optionally) normalize embeddings\n",
        "scores = (embeddings[:1] @ embeddings[1:].T) * 100\n",
        "print(scores.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1EpWSeUcrLT",
        "outputId": "75976f45-fcaf-4aed-ae4a-c2aa9f458b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[63.88489532470703, 87.74205780029297, 66.94505310058594]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computes pairwise cosine similarities between the first input sentence (\"what is the capital of Philippines?\") against remaining ones, multiplying results by 100 for readability purposes."
      ],
      "metadata": {
        "id": "CKeWY1PiBtLG"
      }
    }
  ]
}