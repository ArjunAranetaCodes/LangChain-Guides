{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Zero-shot classification** is a machine learning technique where a model is able to classify text into predefined categories without having seen any examples from those categories during training. This can be useful when we have a large number of possible classes and it would be impractical or time-consuming to train a separate model for each one. The Hugging Face Transformers library provides a simple way to perform zero-shot classification using pre-trained language models such as BART."
      ],
      "metadata": {
        "id": "2VpIdmnHuRwy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Used: https://huggingface.co/facebook/bart-large-mnli"
      ],
      "metadata": {
        "id": "tq4ll-1CuTc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "lo-1oYkVpvqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**!pip install transformers**: This command installs the Hugging Face Transformers library which contains the necessary functionality for performing zero-shot classification."
      ],
      "metadata": {
        "id": "Y__77lGuuWc6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkInjaT2ppef"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"zero-shot-classification\",\n",
        "                      model=\"facebook/bart-large-mnli\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**from transformers import pipeline**: This imports the pipeline function from the transformers module. The pipeline function allows us to easily use pre-trained models for various NLP tasks, including zero-shot classification."
      ],
      "metadata": {
        "id": "nGEcRSbiuYr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_to_classify = \"one day I will see the world\"\n",
        "candidate_labels = ['travel', 'cooking', 'dancing']\n",
        "classifier(sequence_to_classify, candidate_labels)\n",
        "#{'labels': ['travel', 'dancing', 'cooking'],\n",
        "# 'scores': [0.9938651323318481, 0.0032737774308770895, 0.002861034357920289],\n",
        "# 'sequence': 'one day I will see the world'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFuNt0qzp98F",
        "outputId": "468e02be-c060-43c6-c110-cee285655f15"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence': 'one day I will see the world',\n",
              " 'labels': ['travel', 'dancing', 'cooking'],\n",
              " 'scores': [0.9938650727272034, 0.003273802110925317, 0.002861041808500886]}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")**: Here we create a new instance of the Pipeline class specifically for the task of zero-shot classification. We also specify that we want to use the facebook/bart-large-mnli pre-trained model for this task.\n",
        "sequence_to_classify = \"one day I will see the world\": This variable holds the sequence of text that we want to classify. In this example, we are trying to determine what the person is interested in based on their statement.\n",
        "\n",
        "**candidate_labels = ['travel', 'cooking', 'dancing']**: These are the predefined labels that our model can choose from. It's important to note that these labels should match the ones used during training.\n",
        "\n",
        "**classifier(sequence_to_classify, candidate_labels)** : Finally, we call the classifier object with two arguments - the sequence we want to classify and the list of candidate labels. The method returns a dictionary containing three keys:\n",
        "\n",
        "* 'labels' - The original list of candidate labels passed to the method.\n",
        "\n",
        "* 'scores' - A list of scores corresponding to each label representing how confident the model is that the given input belongs to that particular class. The higher the score, the more confidence the model has.\n",
        "\n",
        "* 'sequence' - The input sequence passed to the method.\n",
        "By analyzing the output, we can conclude that the most likely category for the sentence \"one day I will see the world\" is 'travel'."
      ],
      "metadata": {
        "id": "gPIDL8u-ubhy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_labels = ['travel', 'cooking', 'dancing', 'exploration']\n",
        "classifier(sequence_to_classify, candidate_labels, multi_label=True)\n",
        "#{'labels': ['travel', 'exploration', 'dancing', 'cooking'],\n",
        "# 'scores': [0.9945111274719238,\n",
        "#  0.9383890628814697,\n",
        "#  0.0057061901316046715,\n",
        "#  0.0018193122232332826],\n",
        "# 'sequence': 'one day I will see the world'}\n"
      ],
      "metadata": {
        "id": "AJq0ZYZqpuRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With manual PyTorch"
      ],
      "metadata": {
        "id": "97mOAq-zqha_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pose sequence as a NLI premise and label as a hypothesis\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "nli_model = AutoModelForSequenceClassification.from_pretrained('facebook/bart-large-mnli')\n",
        "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')\n"
      ],
      "metadata": {
        "id": "oK4r9NfoqcXi"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_to_classify = \"one day I will see the world\"\n",
        "premise = sequence_to_classify\n",
        "label = 'travel'\n",
        "hypothesis = f'This example is {label}.'\n",
        "\n",
        "# run through model pre-trained on MNLI\n",
        "x = tokenizer.encode(premise, hypothesis, return_tensors='pt',\n",
        "                     truncation_strategy='only_first')\n",
        "logits = nli_model(x.to(\"cpu\"))[0]\n",
        "\n",
        "# we throw away \"neutral\" (dim 1) and take the probability of\n",
        "# \"entailment\" (2) as the probability of the label being true\n",
        "entail_contradiction_logits = logits[:,[0,2]]\n",
        "probs = entail_contradiction_logits.softmax(dim=1)\n",
        "prob_label_is_true = probs[:,1]\n",
        "print(prob_label_is_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVvv5rX2qlHx",
        "outputId": "8eccff25-8a16-40f5-d023-0debfcb33ed0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-3.0856,  2.1139]], grad_fn=<IndexBackward0>)\n",
            "tensor([[0.0055, 0.9945]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.9945], grad_fn=<SelectBackward0>)\n"
          ]
        }
      ]
    }
  ]
}